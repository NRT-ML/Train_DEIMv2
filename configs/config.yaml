# ========================================
# モデル設定
# ========================================
# 使用するモデル名を指定します。
# 利用可能なモデル:
#
# [DEIMv2シリーズ - DINOv3/HGNetv2バックボーン]
#   - deimv2_hgnetv2_atto_coco  (超軽量: 0.5M params, 0.8 GFLOPs, AP 23.8)
#   - deimv2_hgnetv2_femto_coco (軽量: 1.0M params, 1.7 GFLOPs, AP 31.0)
#   - deimv2_hgnetv2_pico_coco  (小型: 1.5M params, 5.2 GFLOPs, AP 38.5)
#   - deimv2_hgnetv2_n_coco     (N: 3.6M params, 6.8 GFLOPs, AP 43.0)
#   - deimv2_hgnetv2_s_coco     (S: 9.7M params, 25.6 GFLOPs, AP 50.9) ← 推奨
#   - deimv2_dinov3_s_coco      (S+: 9.7M params, 25.6 GFLOPs, AP 50.9, DINOv3)
#   - deimv2_dinov3_m_coco      (M: 18.1M params, 52.2 GFLOPs, AP 53.0)
#   - deimv2_dinov3_l_coco      (L: 32.2M params, 96.7 GFLOPs, AP 56.0)
#   - deimv2_dinov3_x_coco      (X: 50.3M params, 151.6 GFLOPs, AP 57.8)
#
# [DEIM-DFINEシリーズ - HGNetv2バックボーン]
#   - deim_hgnetv2_n_coco       (N: 3.1M params, 5.9 GFLOPs)
#   - deim_hgnetv2_s_coco       (S: 9.7M params, 25.7 GFLOPs)
#   - deim_hgnetv2_m_coco       (M: 18.8M params, 56.6 GFLOPs)
#   - deim_hgnetv2_l_coco       (L: 32.8M params, 107.3 GFLOPs)
#   - deim_hgnetv2_x_coco       (X: 57.8M params, 202.9 GFLOPs)
#
# [DFINEシリーズ - HGNetv2バックボーン]
#   - dfine_hgnetv2_n_coco      (N: 3.0M params, 5.8 GFLOPs)
#   - dfine_hgnetv2_s_coco      (S: 9.6M params, 25.6 GFLOPs)
#   - dfine_hgnetv2_m_coco      (M: 18.7M params, 56.5 GFLOPs)
#   - dfine_hgnetv2_l_coco      (L: 32.7M params, 107.2 GFLOPs)
#   - dfine_hgnetv2_x_coco      (X: 57.7M params, 202.8 GFLOPs)
#
# [DEIM-RTDETRv2シリーズ - ResNet/Swinバックボーン]
#   - deim_r18vd_coco           (ResNet-18: 軽量)
#   - deim_r34vd_coco           (ResNet-34: 中型)
#   - deim_r50vd_coco           (ResNet-50: 標準)
#   - deim_r101vd_coco          (ResNet-101: 大型)
#   - deim_swin_t_coco          (Swin-Tiny: Transformer)
#   - deim_swin_s_coco          (Swin-Small: Transformer)
#
model: deimv2_hgnetv2_n_coco

num_classes: # 自動計算。実際のクラス数 + 1(背景クラス)
remap_mscoco_category: False  # カスタムデータセットで訓練する場合

output_dir: "./outputs/deimv2_hgnetv2_n_custom_"

# ========================================
# 訓練設定
# ========================================
epochs: 100

# ========================================
# オプティマイザ設定
# ========================================
optimizer:
  type: AdamW           # オプティマイザの種類
  lr: 0.0004            # 学習率（バッチサイズに応じて線形スケーリング推奨）
  betas: [0.9, 0.999]   # Adam/AdamWのbetaパラメータ
  weight_decay: 0.0001  # 重み減衰（L2正則化）

# ========================================
# 訓練データローダー設定
# ========================================
train_dataloader: 
  collate_fn: {} # 自動設定
  total_batch_size: 4
  dataset: 
    img_folder: datasets\COCOstyle_small\train                                
    ann_file: datasets\COCOstyle_small\annotations\train_annotations.json 
    transforms:
      policy: {} #自動設定
      ops:
        - {
            "type": "Mosaic",
            "fill_value": 0,
            "max_cached_images": 50,
            # "output_size": # image_sizeから自動設定
            "probability": 1.0,
            "random_pop": True,
            "rotation_range": 10,
            "scaling_range": [0.5, 1.5],
            "translation_range": [0.1, 0.1],
            "use_cache": False,
        } # sizeはimage_sizeから自動設定
        - {"type": "RandomPhotometricDistort", "p": 0.5}
        - {"type": "RandomZoomOut", "fill": 0}
        - {"type": "RandomIoUCrop", "p": 0.8}
        - {"type": "SanitizeBoundingBoxes", "min_size": 1}
        - {"type": "RandomHorizontalFlip"}
        - {"type": "Resize"} # sizeはimage_sizeから自動設定
        - {"type": "SanitizeBoundingBoxes", "min_size": 1}
        - {"type": "ConvertPILImage", "dtype": "float32", "scale": True}
        - {"type": "ConvertBoxes", "fmt": "cxcywh", "normalize": True}

# ========================================
# 検証データローダー設定
# ========================================
val_dataloader: 
  total_batch_size: 4
  dataset:
    img_folder: datasets\COCOstyle_small\val                        
    ann_file: datasets\COCOstyle_small\annotations\val_annotations.json 
    transforms:
      ops:
        - {type: Resize}  # sizeはimage_sizeから自動設定
        - {type: ConvertPILImage, dtype: 'float32', scale: true}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: true}