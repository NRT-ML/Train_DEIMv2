# ========================================
# DEIMv2 訓練設定ファイル
# ========================================
# このファイルは、DEIMv2モデルの訓練に必要な設定を定義します。
# src/train.pyスクリプトがこの設定を読み込んで訓練を実行します。

# ========================================
# モデル設定
# ========================================
# 使用するモデル名を指定します。
# 利用可能なモデル:
#
# [DEIMv2シリーズ - DINOv3/HGNetv2バックボーン]
#   - deimv2_hgnetv2_atto_coco  (超軽量: 0.5M params, 0.8 GFLOPs, AP 23.8)
#   - deimv2_hgnetv2_femto_coco (軽量: 1.0M params, 1.7 GFLOPs, AP 31.0)
#   - deimv2_hgnetv2_pico_coco  (小型: 1.5M params, 5.2 GFLOPs, AP 38.5)
#   - deimv2_hgnetv2_n_coco     (N: 3.6M params, 6.8 GFLOPs, AP 43.0)
#   - deimv2_hgnetv2_s_coco     (S: 9.7M params, 25.6 GFLOPs, AP 50.9) ← 推奨
#   - deimv2_dinov3_s_coco      (S+: 9.7M params, 25.6 GFLOPs, AP 50.9, DINOv3)
#   - deimv2_dinov3_m_coco      (M: 18.1M params, 52.2 GFLOPs, AP 53.0)
#   - deimv2_dinov3_l_coco      (L: 32.2M params, 96.7 GFLOPs, AP 56.0)
#   - deimv2_dinov3_x_coco      (X: 50.3M params, 151.6 GFLOPs, AP 57.8)
#
# [DEIM-DFINEシリーズ - HGNetv2バックボーン]
#   - deim_hgnetv2_n_coco       (N: 3.1M params, 5.9 GFLOPs)
#   - deim_hgnetv2_s_coco       (S: 9.7M params, 25.7 GFLOPs)
#   - deim_hgnetv2_m_coco       (M: 18.8M params, 56.6 GFLOPs)
#   - deim_hgnetv2_l_coco       (L: 32.8M params, 107.3 GFLOPs)
#   - deim_hgnetv2_x_coco       (X: 57.8M params, 202.9 GFLOPs)
#
# [DFINEシリーズ - HGNetv2バックボーン]
#   - dfine_hgnetv2_n_coco      (N: 3.0M params, 5.8 GFLOPs)
#   - dfine_hgnetv2_s_coco      (S: 9.6M params, 25.6 GFLOPs)
#   - dfine_hgnetv2_m_coco      (M: 18.7M params, 56.5 GFLOPs)
#   - dfine_hgnetv2_l_coco      (L: 32.7M params, 107.2 GFLOPs)
#   - dfine_hgnetv2_x_coco      (X: 57.7M params, 202.8 GFLOPs)
#
# [DEIM-RTDETRv2シリーズ - ResNet/Swinバックボーン]
#   - deim_r18vd_coco           (ResNet-18: 軽量)
#   - deim_r34vd_coco           (ResNet-34: 中型)
#   - deim_r50vd_coco           (ResNet-50: 標準)
#   - deim_r101vd_coco          (ResNet-101: 大型)
#   - deim_swin_t_coco          (Swin-Tiny: Transformer)
#   - deim_swin_s_coco          (Swin-Small: Transformer)
#
model: deimv2_hgnetv2_atto_coco

# ========================================
# データセット設定
# ========================================
# COCO形式のデータセットを指定します。
# パスは絶対パスまたは相対パス（このファイルからの相対パス）で指定できます。

# 訓練データのアノテーションファイル（COCO JSON形式）
train_ann_file: "datasets/COCOstyle_small/annotations/train_annotations_fixed.json"

# 訓練データの画像フォルダ
train_img_folder: "datasets/COCOstyle_small/train"

# 検証データのアノテーションファイル（COCO JSON形式）
val_ann_file: "datasets/COCOstyle_small/annotations/val_annotations_fixed.json"

# 検証データの画像フォルダ
val_img_folder: "datasets/COCOstyle_small/val"

# ========================================
# 画像設定
# ========================================
# 入力画像のサイズ [height, width] または [size, size]
# Mosaicの出力サイズは自動的にinput_size/2に設定されます
image_size: [320, 320]  # 例: [640, 640], [320, 320], [1280, 1280]

# ========================================
# バッチサイズ設定
# ========================================
# GPUメモリに応じて調整してください
# 推奨: 
#   - 単一GPU (16GB): 8-16
#   - 単一GPU (24GB): 16-32
#   - マルチGPU (4x16GB): 64-128
train_batch_size: 16  # 訓練時のバッチサイズ（複数GPUの場合は合計）
val_batch_size: 8     # 検証時のバッチサイズ

# ========================================
# クラス設定
# ========================================
# データセット内のクラス数
# 注意: DEIMv2では実際のクラス数のみを指定します（背景クラスは含めません）
num_classes: 1  

# COCOカテゴリへのリマップを有効にするかどうか
# カスタムデータセットの場合はFalseに設定
remap_mscoco: false  # true: COCOカテゴリにリマップ, false: カスタムカテゴリを使用

# カテゴリIDを0ベースにリマップするかどうか
# カスタムデータセットでカテゴリIDが1から始まる場合、trueに設定
remap_to_zero_based: true  # true: カテゴリIDを0から始まるように変換

# ========================================
# ポストプロセッサ設定
# ========================================
# 推論時に選択するトップクエリ数
# 小さいデータセットの場合は少なくする（デフォルト: 300）
num_top_queries: 100  # 小さいデータセット用に調整

# ========================================
# 出力設定
# ========================================
# 訓練結果（チェックポイント、ログなど）を保存するディレクトリ
# 注意: 同じディレクトリに既存のチェックポイントがある場合、自動的に訓練が再開されます
output_dir: "./outputs/deimv2_hgnetv2_atto_custom"  # Fish検出モデル（新規訓練）

# ========================================
# 訓練設定
# ========================================
# 訓練エポック数
# 注意: 以下のパラメータは自動的に計算されます（手動で設定することも可能）
#   - no_aug_epoch: 総エポックの13% (データ拡張なしのエポック)
#   - flat_epoch: 総エポックの50% (学習率フラットのエポック)
#   - warmup_iter: 総イテレーションの5% (学習率ウォームアップのイテレーション数)
#   - ema_warmups: 総イテレーションの5% (EMAウォームアップのイテレーション数)
#   - mixup_epochs: [4%, 50%] (Mixup拡張の開始・終了エポック)
#   - stop_epoch: 総エポックの90% (マルチスケール訓練の停止エポック)
#   - data_aug_epochs: [4%, 50%, 90%] (データ拡張の段階的縮小エポック)
#   - matcher_change_epoch: 総エポックの90% (マッチャー変更エポック)
#
# 例: epochs=50の場合の自動設定値
#   - no_aug_epoch: 6 (50 * 0.13)
#   - flat_epoch: 25 (50 * 0.5)
#   - stop_epoch: 45 (50 * 0.9)
#   - data_aug_epochs: [2, 25, 45]
epochs: 50  # 訓練するエポック数

# 手動で設定する場合（オプション）
# no_aug_epoch: 6      # データ拡張なしのエポック数
# flat_epoch: 25       # 学習率フラットのエポック数
# warmup_iter: 500     # ウォームアップイテレーション数
# ema_warmups: 500     # EMAウォームアップイテレーション数
# stop_epoch: 45       # マルチスケール訓練停止エポック

# ========================================
# オプティマイザ設定
# ========================================
optimizer:
  type: AdamW           # オプティマイザの種類
  lr: 0.0004            # 学習率（バッチサイズに応じて線形スケーリング推奨）
  betas: [0.9, 0.999]   # Adam/AdamWのbetaパラメータ
  weight_decay: 0.0001  # 重み減衰（L2正則化）

# ========================================
# データ拡張設定（高度な設定）
# ========================================
# 必要に応じてデータ拡張パイプラインをカスタマイズできます
# 注意: ResizeのsizeとMosaicのoutput_sizeは、image_sizeから自動的に設定されます
#       - Resize.size = image_size
#       - Mosaic.output_size = image_size / 2
#
# また、policy.epochも自動的に計算されます（手動で設定することも可能）:
#       - epoch: [start_epoch, flat_epoch, epoches - no_aug_epoch]
#       - 例: epochs=50の場合 → [2, 25, 45] (4%, 50%, 90%のエポック)
train_dataloader: 
  total_batch_size: 16  # train_batch_sizeと同じ値を設定
  dataset: 
    transforms:
      policy:
        # epochは自動的に計算されます（手動で設定することも可能）
        # epoch: [4, 29, 50]  # [start_epoch, flat_epoch, epoches - no_aug_epoch]
      ops:
        # 最小限のトランスフォームでテスト
        # DEIMv2のカスタムトランスフォームとtorchvision v2の互換性問題を回避
        - {
            "type": "Mosaic",
            "fill_value": 0,
            "max_cached_images": 50,
            # "output_size": # image_sizeから自動設定
            "probability": 1.0,
            "random_pop": True,
            "rotation_range": 10,
            "scaling_range": [0.5, 1.5],
            "translation_range": [0.1, 0.1],
            "use_cache": False,
        } # sizeはimage_sizeから自動設定
        - {"type": "RandomPhotometricDistort", "p": 0.5}
        - {"type": "RandomZoomOut", "fill": 0}
        - {"type": "RandomIoUCrop", "p": 0.8}
        - {"type": "SanitizeBoundingBoxes", "min_size": 1}
        - {"type": "RandomHorizontalFlip"}
        - {"type": "Resize"} # sizeはimage_sizeから自動設定
        - {"type": "SanitizeBoundingBoxes", "min_size": 1}
        - {"type": "ConvertPILImage", "dtype": "float32", "scale": True}
        - {"type": "ConvertBoxes", "fmt": "cxcywh", "normalize": True}

# ========================================
# 検証データローダー設定
# ========================================
eval_dataloader: 
  dataset: 
    transforms:
      ops:
        - {type: Resize}  # sizeはimage_sizeから自動設定
        - {type: ConvertPILImage, dtype: 'float32', scale: true}
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: true}

# ========================================
# 使用例
# ========================================
# 1. 設定ファイルを編集して、データセットパスやハイパーパラメータを設定
# 
# 2. 単一GPU訓練:
#    python src/train.py
#
# 3. マルチGPU訓練（4 GPU）:
#    CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --master_port=7777 --nproc_per_node=4 src/train.py
#
# 4. カスタム設定ファイルを使用:
#    python src/train.py --config path/to/custom_config.yaml
#
# 5. チェックポイントから再開:
#    python src/train.py --resume outputs/checkpoint.pth
#
# 6. AMP（自動混合精度）を有効化:
#    python src/train.py --use-amp
#
# 7. 評価のみ:
#    python src/train.py --test-only --resume outputs/best.pth